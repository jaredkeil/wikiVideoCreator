{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from collections import OrderedDict, namedtuple\n",
    "import time\n",
    "from datetime import datetime\n",
    "import codecs\n",
    "from textwrap import wrap\n",
    "\n",
    "import numpy as np\n",
    "import wikipediaapi\n",
    "from moviepy.editor import *\n",
    "from gtts import gTTS\n",
    "from skimage.io import imread, imsave\n",
    "from skimage import transform\n",
    "from skimage.util import img_as_ubyte\n",
    "\n",
    "from image_downloader import master_download\n",
    "from im_funcs import maxsize_pad\n",
    "\n",
    "from synthesize import synthesize\n",
    "from hyperparams import Hyperparams as hp\n",
    "from data_load import *\n",
    "\n",
    "\n",
    "# Default Parameters\n",
    "WHITE = (255, 255, 255)\n",
    "BLACK = (0, 0, 0)\n",
    "WHITE_GIZEH = (1, 1, 1)\n",
    "BLACK_GIZEH = (0, 0, 0)\n",
    "\n",
    "VIDEO_SIZE = (1920, 1080)\n",
    "IMG_SHAPE = (1080, 1920)\n",
    "IMG_DISPLAY_DURATION = 4    #duration, in seconds, to display each image\n",
    "\n",
    "excluded_sections = {'See also', 'References', 'Further reading', 'External links',\n",
    "                'Formats and track listings', 'Credits and personnel', 'Charts',\n",
    "                'Certifications', 'Release history'}\n",
    "\n",
    "stops = {'e.g.', '[sic]', '[...]', 'i.e.'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Bokmål'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wiki = wikipediaapi.Wikipedia('en')\n",
    "page = wiki.page('Bokmål')\n",
    "page.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Workflow:\n",
    "\n",
    "- Initialize WikiMovie with page\n",
    "- Create txt file\n",
    "    - Title,\n",
    "    - Summary text,\n",
    "    - Section1 title,\n",
    "    - Section1 text, \n",
    "    - etc ....\n",
    "- Output all .wav speech files with synthesize function\n",
    "-  ... currently just name files 0.wav, 1.wav, 2 ....\n",
    "- Generate clips:\n",
    "    Possible output:\n",
    "    - textclip, imageseq with 0.wav (section with text to read)\n",
    "    - textclip with 1.wav (section without text)\n",
    "\n",
    "    \n",
    "Basically, will have to iterate through output samples directory (possibly with just index 'i' for filepath),\n",
    "and link them back with the text.\n",
    "\n",
    "If Section has no text, it's just a main header... ex: `{'History': '', 'Ancient times': 'blah blah...'}`\n",
    "\n",
    "Create textclip for 'History', set audio, and go on to next, e.g. 'Ancient times'\n",
    "\n",
    "If value at the key is not empty, create textclip as above, AND Image Sequence.\n",
    "\n",
    "For each item try to make one piece of audio continue through Textclip display and Image sequence if necessary.\n",
    "Maybe just set the section header durations to be a little long, like 3 secs. The actual paragraph may start in sooner but at least the audio won't get cutoff, and don't have to synthesize the section title audio separately on a different line of the text file.\n",
    "\n",
    "    \n",
    "|   audio ---------| ------------> |\n",
    "|----------------:|:--------------|\n",
    "| /Section title + |         Text/ |\n",
    "| TextClip         | ImageSequence |\n",
    "\n",
    "\n",
    "- Pass the dict into text file as `script[i]['title'] + '. ' + script[i]['text']`\n",
    "  \n",
    "  (notice the space after the period)\n",
    "  \n",
    "- Also process the script dictionary for creating "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiMovie():\n",
    "    \"\"\"\n",
    "    Make movies in standard format (.mp4) from wikipedia pages.\n",
    "    Initialize with 'page' object from wikipedia Python module.\n",
    "    Primary user function is make_movie().\n",
    "    \"\"\"\n",
    "    def __init__(self, page, narrator='gtts'):\n",
    "        self.page = page\n",
    "        self.title = self.page._attributes['title']\n",
    "        self.narrator = narrator\n",
    "        self.script = [{'title': page.title, \n",
    "                        'level': 0, \n",
    "                        'text': self.clean_text(page.summary)}]\n",
    "        self.cliplist = []\n",
    "        \n",
    "        # self.p = Path(__file__).resolve().parents[1]\n",
    "        self.p = Path(os.path.abspath('')).resolve() ## For jupyter notebook\n",
    "        self._imgidx = 0\n",
    "        self.cutoff = None\n",
    "        self.longest= 0\n",
    "        \n",
    "\n",
    "    def _create_paths(self):\n",
    "        # Image directories\n",
    "        self.parent_images = self.p / 'images'\n",
    "        self.imgdir = self.p / 'images' / self.title\n",
    "        self.resizedir = self.imgdir / 'resize'\n",
    "        # gTTS audio directories\n",
    "        self.parent_audio = self.p / 'audio'\n",
    "        self.auddir = self.p / 'audio' / self.title\n",
    "        # dc_tts directory\n",
    "        self.dctts_dir = self.p / 'dc_tts'\n",
    "        self.dctts_in = self.dctts_dir / 'text_input'\n",
    "        self.dctts_out = self.dctts_dir / 'samples' / self.title\n",
    "        # URL lists text files directory\n",
    "        self.url_dir = self.p / 'url_files'\n",
    "        # Video directory (all article videos stored in folder, files named by title)\n",
    "        self.viddir = self.p / 'videos'\n",
    "        # Video save path\n",
    "        self.vidpath = self.viddir / (self.title + \".mp4\")\n",
    "\n",
    "        print('creating paths...')\n",
    "        for d in [self.parent_images, self.imgdir, self.resizedir,\\\n",
    "                self.parent_audio, self.auddir, self.dctts_dir,\\\n",
    "                self.dctts_in, self.dctts_out, self.url_dir, self.viddir]:\n",
    "            if not d.exists():\n",
    "                d.mkdir()\n",
    "                print(d, \"directory created\")\n",
    "            elif d.exists():\n",
    "                print(d, \"exists\")\n",
    "\n",
    "    def _resize_images(self):\n",
    "        self._imgpaths = []\n",
    "        contents = self.imgdir.glob('*')\n",
    "        fnames =  [x for x in contents if x.is_file() and x.parts[-1][0] != '.']\n",
    "        self.fixed_durations = [IMG_DISPLAY_DURATION for _ in fnames]\n",
    "        \n",
    "        n_imgs = len(fnames)\n",
    "        for i, fname in enumerate(fnames):\n",
    "            sys.stdout.write(f\"Resizing Images [{'#' * (i+1) + ' ' * (n_imgs-i-1)}]   \\r\")\n",
    "            sys.stdout.flush()\n",
    "            \n",
    "            path = str(self.imgdir / fname)\n",
    "            print(path)\n",
    "            save_path = str(self.resizedir / fname)\n",
    "            print(self.resizedir)\n",
    "            print(save_path)\n",
    "            try:\n",
    "                maxsize_pad(path, save_path)\n",
    "            except Exception:\n",
    "                continue\n",
    "            self._imgpaths.append(save_path)\n",
    "\n",
    "\n",
    "    def make_narration(self, string, mp3path):\n",
    "        if self.narrator == 'dc_tts':\n",
    "            synthesize()\n",
    "        else:\n",
    "                             \n",
    "        tts = gTTS(string)\n",
    "        tts.save(mp3path)\n",
    "        return AudioFileClip(mp3path)\n",
    "\n",
    "\n",
    "    def _add_ImageSequence(self, audioclip):\n",
    "        \"\"\"add image with soundtrack audioclip of narrated text\"\"\"\n",
    "        ### Cycle through images so it doesn't always start at the first one\n",
    "        tmp_imgpaths = self._imgpaths[self._imgidx:] + self._imgpaths[:self._imgidx]\n",
    "        self._imgidx += 1\n",
    "        image_sequence = ImageSequenceClip(sequence=tmp_imgpaths,\n",
    "                                durations=self.fixed_durations, load_images=True).\\\n",
    "                            set_position(('center', 400)).\\\n",
    "                            fx(vfx.loop, duration=audioclip.duration).\\\n",
    "                            set_audio(audioclip)\n",
    "        self.cliplist.append(image_sequence)\n",
    "\n",
    "\n",
    "    def _add_subsection(self, section, level):\n",
    "        \"\"\"\n",
    "        Add textclip of section titles.\n",
    "        If it's just a main header followed by subsections, NO image sequence.\n",
    "        If section contains text, create narratation and image sequence.\n",
    "        \"\"\"\n",
    "\n",
    "        mp3path_header = os.path.join(self.auddir, section.title + '_header.mp3')\n",
    "        ac_header = self._make_narration(section.title, mp3path_header)\n",
    "        fontsize = 130 - (30 * level) # higher level means deeper 'indentation'\n",
    "        tc_header = TextClip(section.title, color='white', fontsize=fontsize, \n",
    "                    size=VIDEO_SIZE, method='caption').\\\n",
    "                    set_audio(ac_header).set_duration(ac_header.duration)\n",
    "        self.cliplist.append(tc_header)\n",
    "        ## if there is an actual paragraph in the section, create an image sequence for it\n",
    "        if section.text:\n",
    "            mp3path_text = os.path.join(self.auddir, section.title + '_text.mp3')\n",
    "            ac_text = self._make_narration(section.text[:self.cutoff], mp3path_text)\n",
    "            self._add_ImageSequence(ac_text)\n",
    "\n",
    "        print(section.title, \"complete\")\n",
    "                             \n",
    "    def clean_text(self, text):\n",
    "        \"\"\"\n",
    "        Remove stop words\n",
    "        \"\"\"\n",
    "        for x in stops:\n",
    "            if x in text:\n",
    "                print(x, \"in text\")\n",
    "            text = text.replace(x, '')\n",
    "        return text\n",
    "\n",
    "    def flush_sections(self, sections, level=0):\n",
    "        \"\"\"\n",
    "        Get text from all levels (sections, subsections) in page order and generate narrations\n",
    "        \"\"\"\n",
    "        for s in sections:\n",
    "            if s.title in excluded_sections:\n",
    "                print('exluding')\n",
    "                continue\n",
    "            else:\n",
    "                self.script.append({'title':s.title, \n",
    "                                    'level': level+1, \n",
    "                                    'text': self.clean_text(s.text)})\n",
    "                # self._add_subsection(s, level) # clip creation\n",
    "                # recursion to next level. Once lowest level is reached, next main section will be accessed\n",
    "                self.flush_sections(s.sections, level+1)\n",
    "        \n",
    "    def output_text(self):\n",
    "        \"\"\"\n",
    "        Process page text for TTS creation. Write to file. \n",
    "        \"\"\"\n",
    "        self.sent_path = self.dctts_in / f\"{self.title}.txt\"\n",
    "        hp.test_data = self.sent_path\n",
    "        \n",
    "        with self.sent_path.open('w') as sf:\n",
    "            sf.write(f\"Script for Wikipedia article {self.title}\\n\")\n",
    "            \n",
    "            # Section by section\n",
    "            for d in self.script[:1]:\n",
    "                # d = {'title': section title, 'level': level, 'text': section text}\n",
    "\n",
    "                # Full length sentences, possibly greater than \n",
    "                full_sents = [d['title']] + d['text'].split('.')\n",
    "                             \n",
    "                # break section down into max 180 character chunks  \n",
    "                sents = []\n",
    "                for sent in (full_sents):\n",
    "                    if len(sent) > hp.max_N:\n",
    "                        split_on = sent[:hp.max_N].rfind(\" \")\n",
    "                        tmp_split = [sent[:split_on], sent[split_on:]]\n",
    "                        while len(tmp_split[-1]) > hp.max_N:\n",
    "                            last = tmp_split.pop()\n",
    "                            split_on = last[:hp.max_N].rfind(\" \")\n",
    "                            tmp_split += [last[:split_on], last[split_on:]]\n",
    "                        sents.extend(tmp_split)     \n",
    "                    else:\n",
    "                        sents.append(sent)         \n",
    "                     \n",
    "                for i, sent in enumerate(sents):     \n",
    "                    sf.write(f\"{d['title']}:{i} {sent}\\n\")\n",
    "    \n",
    "    def create_clips():\n",
    "        pass\n",
    "                         \n",
    "    def make_movie(self, cutoff=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            cutoff (int): Limit the length of the script. Used like script[:cutoff]\n",
    "        Returns:\n",
    "            None\n",
    "        \"\"\"\n",
    "        print(\"Video Title: \", self.title)\n",
    "        self.cutoff = cutoff\n",
    "        self._create_paths()\n",
    "        \n",
    "        self.output_text()\n",
    "        self.make_narration()\n",
    "        # Download and resize images\n",
    "        master_download(main_keyword=self.title, \n",
    "                        url_dir=self.url_dir, img_dir=self.imgdir, num_requested=20)\n",
    "        self._resize_images()\n",
    "        print('\\n') \n",
    "                             \n",
    "        # Create Video Clips\n",
    "        print(\"Creating clips. . .\")\n",
    "#         self._flush_page()\n",
    "\n",
    "                             \n",
    "        thanks = TextClip(\"Thanks for watching \\n and listening\",\n",
    "                            color='white', fontsize=72, size=VIDEO_SIZE, method='caption').\\\n",
    "                            set_duration(2)\n",
    "\n",
    "        subscribe = TextClip(\"Please Subscribe!\",\n",
    "                                color='white', fontsize=72, size=VIDEO_SIZE, method='caption').\\\n",
    "                                set_duration(2)\n",
    "\n",
    "        self.video = concatenate_videoclips(self.cliplist + [thanks, subscribe],\n",
    "                                            method='compose').\\\n",
    "                                            on_color(color=BLACK, col_opacity=1)\n",
    "        # Encode Video\n",
    "        start = datetime.now()\n",
    "        self.video.write_videofile(str(self.vidpath) , fps=1, codec='mpeg4', \n",
    "                                   audio_codec=\"aac\", preset='ultrafast')\n",
    "        dur = datetime.now() - start\n",
    "        print(\"Video Encoding completed in time: \", dur)\n",
    "\n",
    "        # self.audio_clip.close()\n",
    "        # title_text.close()\n",
    "        thanks.close()\n",
    "        subscribe.close()\n",
    "        self.video.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[...] in text\n",
      "e.g. in text\n",
      "[sic] in text\n"
     ]
    }
   ],
   "source": [
    "WMM = WikiMovie(page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating paths...\n",
      "/Users/jared/video-creater/images exists\n",
      "/Users/jared/video-creater/images/Bokmål exists\n",
      "/Users/jared/video-creater/images/Bokmål/resize exists\n",
      "/Users/jared/video-creater/audio exists\n",
      "/Users/jared/video-creater/audio/Bokmål exists\n",
      "/Users/jared/video-creater/dc_tts exists\n",
      "/Users/jared/video-creater/dc_tts/text_input exists\n",
      "/Users/jared/video-creater/dc_tts/samples/Bokmål exists\n",
      "/Users/jared/video-creater/url_files exists\n",
      "/Users/jared/video-creater/videos exists\n"
     ]
    }
   ],
   "source": [
    "WMM._create_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exluding\n"
     ]
    }
   ],
   "source": [
    "WMM.flush_sections(page.sections)\n",
    "WMM.output_text()\n",
    "hp.test_data = str(WMM.sent_path)\n",
    "hp.sampledir = str(WMM.dctts_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = codecs.open(WMM.sent_path, 'r', 'utf-8').readlines()[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bokmål:0 Bokmål\\n',\n",
       " 'Bokmål:1 Bokmål (UK: , US: ; literally \"book tongue\") is an official written standard for the Norwegian language, alongside Nynorsk\\n',\n",
       " 'Bokmål:2  Bokmål is the preferred written standard of Norwegian for 85% to 90% of the population in Norway\\n',\n",
       " 'Bokmål:3  Unlike, for instance, the Italian language, there is no nationwide standard or agreement on the pronunciation of Bokmål\\n',\n",
       " 'Bokmål:4 \\n',\n",
       " 'Bokmål is regulated by the governmental Norwegian Language Council\\n',\n",
       " 'Bokmål:5  A more conservative orthographic standard, commonly known as Riksmål, is regulated by the non-governmental Norwegian Academy for Language and Literature\\n',\n",
       " 'Bokmål:6  The written standard is a Norwegianised variety of the Danish language\\n',\n",
       " 'Bokmål:7 \\n',\n",
       " 'The first Bokmål orthography was officially adopted in 1907 under the name Riksmål after being under development since 1879\\n',\n",
       " 'Bokmål:8  The architects behind the reform were Marius Nygaard and Jacob Jonathan Aars\\n',\n",
       " 'Bokmål:9  It was an adaptation of written Danish, which was commonly used since the past union with Denmark, to the Dano-Norwegian koiné spoken by the Norwegian urban elite, especially in\\n',\n",
       " 'Bokmål:10  the capital\\n',\n",
       " 'Bokmål:11  When the large conservative newspaper Aftenposten adopted the 1907 orthography in 1923, Danish writing was practically out of use in Norway\\n',\n",
       " 'Bokmål:12  The name Bokmål was officially adopted in 1929 after a proposition to call the written language Dano-Norwegian lost by a single vote in the Lagting (a chamber in the Norwegian\\n',\n",
       " 'Bokmål:13  parliament)\\n',\n",
       " \"Bokmål:14 The government does not regulate spoken Bokmål and recommends that normalised pronunciation should follow the phonology of the speaker's local dialect\\n\",\n",
       " 'Bokmål:15  Nevertheless, there is a spoken variety of Norwegian that, in the region of South-Eastern Norway, is commonly seen as the de facto standard for spoken Bokmål\\n',\n",
       " 'Bokmål:16  In The Phonology of Norwegian, Gjert Kristoffersen writes that\\n',\n",
       " '\\n',\n",
       " 'Bokmål  is in its most common variety looked upon as reflecting formal middle-class urban speech, especially that\\n',\n",
       " 'Bokmål:17  found in the eastern part of Southern Norway , with the capital Oslo as the obvious centre\\n',\n",
       " 'Bokmål:18  One can therefore say that Bokmål has a spoken realisation that one might call an unofficial standard spoken Norwegian\\n',\n",
       " \"Bokmål:19  It is in fact often referred to as Standard Østnorsk ('Standard East Norwegian')\\n\",\n",
       " 'Bokmål:20 \\n',\n",
       " 'Standard Østnorsk (Standard East Norwegian) is the pronunciation most commonly given in dictionaries and taught to foreigners in Norwegian language classes\\n',\n",
       " 'Bokmål:21  Standard Østnorsk as a spoken language is not used and does not have any particular prestige outside South-Eastern Norway\\n',\n",
       " 'Bokmål:22  All spoken variations of the Norwegian language are used  in the Storting and in Norwegian national broadcasters such as NRK and TV 2, even in cases where the conventions of\\n',\n",
       " 'Bokmål:23  Bokmål are used\\n',\n",
       " 'Bokmål:24  The spoken variation typically reflects the region the person grew up in\\n',\n",
       " 'Bokmål:25 \\n']"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = [text_normalize(line.split(\" \", 1)[-1]).strip() + \"E\" for line in lines] # text normalization, E: EOS\n",
    "sents = [s for s in sents if s != 'E']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bokmalE',\n",
       " 'bokmal uk us literally book tongue is an official written standard for the norwegian language alongside nynorskE',\n",
       " 'bokmal is the preferred written standard of norwegian for to of the population in norwayE',\n",
       " 'unlike for instance the italian language there is no nationwide standard or agreement on the pronunciation of bokmalE',\n",
       " 'is regulated by the governmental norwegian language councilE',\n",
       " 'a more conservative orthographic standard commonly known as riksmal is regulated by the non governmental norwegian academy for language and literatureE',\n",
       " 'the written standard is a norwegianised variety of the danish languageE',\n",
       " 'first bokmal orthography was officially adopted in under the name riksmal after being under development sinceE',\n",
       " 'the architects behind the reform were marius nygaard and jacob jonathan aarsE',\n",
       " 'it was an adaptation of written danish which was commonly used since the past union with denmark to the dano norwegian koine spoken by the norwegian urban elite especially inE',\n",
       " 'the capitalE',\n",
       " 'when the large conservative newspaper aftenposten adopted the orthography in danish writing was practically out of use in norwayE',\n",
       " 'the name bokmal was officially adopted in after a proposition to call the written language dano norwegian lost by a single vote in the lagting a chamber in the norwegianE',\n",
       " 'parliamentE',\n",
       " \"the government does not regulate spoken bokmal and recommends that normalised pronunciation should follow the phonology of the speaker's local dialectE\",\n",
       " 'nevertheless there is a spoken variety of norwegian that in the region of south eastern norway is commonly seen as the de facto standard for spoken bokmalE',\n",
       " 'in the phonology of norwegian gjert kristoffersen writes thatE',\n",
       " 'is in its most common variety looked upon as reflecting formal middle class urban speech especially thatE',\n",
       " 'found in the eastern part of southern norway with the capital oslo as the obvious centreE',\n",
       " 'one can therefore say that bokmal has a spoken realisation that one might call an unofficial standard spoken norwegianE',\n",
       " \"it is in fact often referred to as standard stnorsk 'standard east norwegian'E\",\n",
       " 'stnorsk standard east norwegian is the pronunciation most commonly given in dictionaries and taught to foreigners in norwegian language classesE',\n",
       " 'standard stnorsk as a spoken language is not used and does not have any particular prestige outside south eastern norwayE',\n",
       " 'all spoken variations of the norwegian language are used in the storting and in norwegian national broadcasters such as nrk and tv even in cases where the conventions ofE',\n",
       " 'bokmal are usedE',\n",
       " 'the spoken variation typically reflects the region the person grew up inE']"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 samples, 180 characters (max) each\n"
     ]
    }
   ],
   "source": [
    "char2idx, idx2char = load_vocab()\n",
    "texts = np.zeros((len(sents), hp.max_N), np.int32)\n",
    "for i, sent in enumerate(sents):\n",
    "    texts[i, :len(sent)] = [char2idx[char] for char in sent]\n",
    "\n",
    "print(f\"{texts.shape[0]} samples, {texts.shape[1]} characters (max) each\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A sample of the text encoding\n",
      "[[ 4 17 13 15  3 14  1  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 4 17 13 15  3 14  2 23 13  2 23 21  2 14 11 22  7 20  3 14]\n",
      " [ 4 17 13 15  3 14  2 11 21  2 22 10  7  2 18 20  7  8  7 20]\n",
      " [23 16 14 11 13  7  2  8 17 20  2 11 16 21 22  3 16  5  7  2]\n",
      " [11 21  2 20  7  9 23 14  3 22  7  6  2  4 27  2 22 10  7  2]]\n"
     ]
    }
   ],
   "source": [
    "print(\"A sample of the text encoding\")\n",
    "print(texts[:5, :20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/jared/video-creater/train.py:48: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/train.py:53: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/modules.py:32: The name tf.get_variable is deprecated. Please use tf.compat.v1.get_variable instead.\n",
      "\n",
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/modules.py:134: conv1d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv1D` instead.\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/modules.py:139: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/networks.py:140: The name tf.rsqrt is deprecated. Please use tf.math.rsqrt instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/networks.py:140: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/networks.py:147: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/modules.py:239: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2DTranspose` instead.\n",
      "Graph loaded\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/synthesize.py:28: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jared/video-creater/synthesize.py:33: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/jared/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "INFO:tensorflow:Restoring parameters from LJ_logdir/LJ01-1/model_gs_724k\n",
      "Text2Mel Restored!\n",
      "INFO:tensorflow:Restoring parameters from LJ_logdir/LJ01-2/model_gs_718k\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/210 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSRN Restored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 210/210 [19:00<00:00,  5.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on file 1\n",
      "Working on file 2\n",
      "Working on file 3\n",
      "Working on file 4\n",
      "Working on file 5\n",
      "Working on file 6\n",
      "Working on file 7\n",
      "Working on file 8\n",
      "Working on file 9\n",
      "Working on file 10\n",
      "Working on file 11\n",
      "Working on file 12\n",
      "Working on file 13\n",
      "Working on file 14\n",
      "Working on file 15\n",
      "Working on file 16\n",
      "Working on file 17\n",
      "Working on file 18\n",
      "Working on file 19\n",
      "Working on file 20\n",
      "Working on file 21\n",
      "Working on file 22\n",
      "Working on file 23\n",
      "Working on file 24\n",
      "Working on file 25\n",
      "Working on file 26\n",
      "Working on file 27\n",
      "Working on file 28\n",
      "Working on file 29\n",
      "Working on file 30\n",
      "Working on file 31\n"
     ]
    }
   ],
   "source": [
    "synthesize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
